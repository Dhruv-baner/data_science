{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7bc3f4",
   "metadata": {},
   "source": [
    "### **Table of Contents**\n",
    "\n",
    "1. **Problem Definition**\n",
    "    - 1.1: Problem Classification\n",
    "    - 1.2: Defining Success Metrics\n",
    "    - 1.3: \n",
    "\n",
    "2. **Data Collection** \n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**\n",
    "    - 3.1: Data Quality Dimensions\n",
    "    - 3.2: Univariate Analysis\n",
    "    - 3.3: Bivariate Analysis\n",
    "    - 3.4: Multivariate Analysis\n",
    "\n",
    "4. **Data Cleaning and Preprocessing** \n",
    "    - 4.1: Handling Missing Values\n",
    "    - 4.2: Handling Outliers\n",
    "    - 4.3: Data Type Correction\n",
    "    - 4.4: Duplicates Removal \n",
    "    - 4.5: Data Transformation\n",
    "\n",
    "5. **Feature Engineering** \n",
    "    - 5.1: Feature Creation\n",
    "    - 5.2: Feature Selection\n",
    "    - 5.3: Feature Scaling\n",
    "\n",
    "6. **Data Splitting**\n",
    "    - Train-Test Split\n",
    "    - Cross Validation\n",
    "    - Time Series Split\n",
    "\n",
    "7. **Machine Learning: A Practical Overview**\n",
    "    - 7.1 Baseline Model\n",
    "    - 7.2 Linear Models\n",
    "       - Linear Regression\n",
    "       - Logistic Regression\n",
    "       - Ridge/Lasso Regression\n",
    "    - 7.3 Tree-Based Models\n",
    "       - Decision Trees\n",
    "       - Random Forest\n",
    "       - Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "    - 7.4 Other Algorithms\n",
    "       - K-Nearest Neighbors (KNN)\n",
    "       - Naive Bayes\n",
    "       - Support Vector Machines (SVM)\n",
    "    - 7.5 Model Selection & Comparison\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52b38c",
   "metadata": {},
   "source": [
    "### **Part 1.1: Problem Classification** \n",
    "\n",
    "- Correctly identify the problem you are trying to solve \n",
    "\n",
    "- Within the first 30 seconds, follow the step-by-step process \n",
    "1. Listen to the problem at hand \n",
    "2. Immediately classify the problem by considering: \n",
    "    - Is this a supervised or unsupervised learning problem?\n",
    "    - If supervised: Is this a regression or classification problem?\n",
    "    - If unsupervised: Is this a clustering or dimensionality reduction problem?\n",
    "3. Understand the objective: Prediction, causal inference or finding patterns?\n",
    "4. Confirm with the stakeholders that your understanding is correct\n",
    "\n",
    "**Supervised Learning:** You have labeled data. Your goal is to learn a function that maps inputs to outputs:\n",
    "- Regression: Predicting a continuous value \n",
    "- Classification: Predicting a discrete value (class labels)\n",
    "\n",
    "**Unsupervised Learning:** You have unlabeled data. Your goal is to find patterns or structure in the data.\n",
    "- Clustering: Grouping similar data points together\n",
    "- Dimensionality Reduction: Reducing the number of features while preserving important information\n",
    "\n",
    "**Prediction**\n",
    "- Question: \"What will happen?\"\n",
    "- Goal: Forecast outcomes accurately\n",
    "- Example: \"Which customers will churn?\"\n",
    "- Don't care about WHY - just want accurate predictions.\n",
    "\n",
    "**Causal Inference**\n",
    "- Question: \"What CAUSED this?\" or \"What IF we do X?\"\n",
    "- Goal: Understand cause-and-effect for decision-making\n",
    "- Example: \"Will offering discounts CAUSE customers to stay?\"\n",
    "- Care deeply about WHY - need to know what actually works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea900e",
   "metadata": {},
   "source": [
    "### **Part 1.2 Defining Success Metrics**\n",
    "\n",
    "Before diving into the data you need to be able to define what business success looks like to your stakeholders\n",
    "\n",
    "The **SMART Framework** is a useful tool to define success metrics: \n",
    "- Specific: Clear definition of what you want\n",
    "- Measurable: Quantifiable indicators or outcome\n",
    "- Achievable: Realistic goals, considering constraints \n",
    "- Relevant: Tied to business objectives\n",
    "- Time bound: Clear deadlines for acheivement\n",
    "\n",
    "**Baseline:** This is the current performance level before you do anything. You goal is to beat this baseline by adding value \n",
    "*Example: Current churn rate: 20%*\n",
    "\n",
    "**Target:** the desired performance level after intervention. Should be a specific, quantified goal. Be realisitc: 10-30% improvement is standard. *Example: Reduce churn to 15% (25% relative reduction)*\n",
    "\n",
    "Note: Also mention the business value of hitting the target. *Example: This would save $500K annually in revenue*\n",
    "\n",
    "**Minimum Viable Performance**: The lowest acceptable performance level to consider the project a success. Helps manage expectations. *Example: Reduce churn to 18% (10% relative reduction)*\n",
    "\n",
    "**Constraints**: Understand the real world limitations that affect feasibility\n",
    "- Budget: Financial limits on resources\n",
    "- Time: Deadlines for delivery\n",
    "- Resources: Availability of data, tools, personnel\n",
    "\n",
    "Break success down into two components: \n",
    "\n",
    "1. **Business Success**: The business outcome we are trying to acheive, measured in business units: Dollars, percentages, customer counts, time saved, etc. *Example: Increase revenue by $1M annually*\n",
    "\n",
    "2. **Model Success**: The technical performance of the machine learning model, measured in ML metrics: Accuracy, precision, recall, F1-score, RMSE, AUC-ROC, etc. *Example: Achieve 85% accuracy on test set*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f4d82",
   "metadata": {},
   "source": [
    "### **Part 3.1: Data Quality Assessment**\n",
    "\n",
    "The first step before any analysis is to understand the quality of data . There are six main dimensions of data quality we need to assess. \n",
    "\n",
    "1. **Completeness**: Do we actually have all the required data points\n",
    "- Check for missing values in key columns. Understand how many fields are missing, what percentage of each column is missing, and are there rows that are largely empty. \n",
    "\n",
    "- Then check for missingness patterns. Are the missing vaslues random or systematic? Is there any correlation between missingness? \n",
    "\n",
    "- Things to look out for: \n",
    "    - If missingness correlates with target = Results are biased\n",
    "    - If entire columns/rows are missing = Data pipeline issues \n",
    "    - If  over 30% of data is missing in key fields = Impute or use alternative data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "\n",
    "# Check percentage of missing values\n",
    "missing_pct = df.isnull().sum() / len(df) * 100\n",
    "\n",
    "# To summarise the two together\n",
    "missing_summary = pd.DataFrame({\n",
    "    'missing_count': missing,\n",
    "    'missing_pct': missing_pct\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "\n",
    "# Visualise missingness pattern \n",
    "import missingno as msno\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n",
    "# Visualise correlation between missingness\n",
    "msno.heatmap(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1b0dd",
   "metadata": {},
   "source": [
    "2. **Accuracy:** Is the data correct and reliable. \n",
    "- Impossible values: Negative ages, future dates, out-of-range values = Data collection/entry errors\n",
    "- Data entry errors: Typos, inconsistent formats, duplicates = Human error\n",
    "- Outliers: Values that are extreme and likely erroneous = Measurement errors\n",
    "\n",
    "- **Use summary statistics to identify these anomalies, or visualisations liek boxplots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "df.describe()  # Check min, max, mean\n",
    "\n",
    "# Check for impossible values\n",
    "df[df['age'] < 0]  # Negative ages\n",
    "df[df['age'] > 120]  # Unrealistic ages\n",
    "df[df['price'] < 0]  # Negative prices\n",
    "\n",
    "# Value counts for categories\n",
    "df['category'].value_counts()  # Spot typos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb526667",
   "metadata": {},
   "source": [
    "3. **Consistency:** Is the data consistent across different sources and formats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check date formats\n",
    "pd.to_datetime(df['date'], errors='coerce').isnull().sum()\n",
    "\n",
    "# Check cross-field logic\n",
    "df[df['end_date'] < df['start_date']]  # Illogical dates\n",
    "\n",
    "# Check for sudden changes\n",
    "df.groupby('date')['revenue'].mean().plot()  # Visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a99d0a2",
   "metadata": {},
   "source": [
    "4. **Validity:** Does the data conform to defined formats, types, and ranges?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check email format\n",
    "import re\n",
    "email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "df['email'].str.match(email_pattern).value_counts()\n",
    "\n",
    "# Check category validity\n",
    "valid_categories = ['A', 'B', 'C']\n",
    "invalid = df[~df['category'].isin(valid_categories)]\n",
    "\n",
    "# Check business rules\n",
    "df[df['discount'] > df['price']]  # Invalid discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a2a93",
   "metadata": {},
   "source": [
    "5. **Uniqueness:** Are there duplicate records or entries in the dataset?\n",
    "\n",
    "- Check for exact duplicates, such as completely identical rows\n",
    "\n",
    "- Check for partial duplicates based on key identifiers, such as same customer ID but different names\n",
    "\n",
    "- Check for primary key violations: Expected unique ID's are not unique, multiple records for the same entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for exact duplicates\n",
    "df.duplicated().sum()\n",
    "df[df.duplicated(keep=False)]  # Show all duplicates\n",
    "\n",
    "# Check primary key uniqueness\n",
    "df['customer_id'].nunique() == len(df)\n",
    "\n",
    "# Check for near-duplicates\n",
    "df.groupby(['customer_id', 'date']).size()[lambda x: x > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e234a98",
   "metadata": {},
   "source": [
    "6. **Timeliness:** Is the data up-to-date and relevant for the analysis?\n",
    "\n",
    "- Freshness: When was the data last updated, and is it recent enough for the use case\n",
    "\n",
    "- Update Frequency: Is the data updates as scheduleed, or are there gaps in time series data\n",
    "\n",
    "- Lag: Is there a delay between data generation and availability for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check latest date\n",
    "df['date'].max()\n",
    "\n",
    "# Check for gaps in time-series\n",
    "date_range = pd.date_range(df['date'].min(), df['date'].max(), freq='D')\n",
    "missing_dates = date_range.difference(df['date'])\n",
    "\n",
    "# Check update frequency\n",
    "df.groupby('date').size().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853262b",
   "metadata": {},
   "source": [
    "### **Part 3.2: Univariate Analysis** \n",
    "Analysing individual variables to understand distribution, tendencies, variance\n",
    "\n",
    "**Numerical Variables**\n",
    "\n",
    "- Distribution Shape: Is it normally distributed, skewed, bimodal? \n",
    "- Central Tendency: Mean, median, mode\n",
    "- Dispersion: Range, variance, standard deviation, interquartile range\n",
    "- Outliers: Identify extreme values using boxplots, z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6668841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central tendency\n",
    "df['age'].mean()\n",
    "df['age'].median()\n",
    "df['age'].mode()\n",
    "\n",
    "# Spread\n",
    "df['age'].std()\n",
    "df['age'].var()\n",
    "df['age'].min()\n",
    "df['age'].max()\n",
    "df['age'].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Quick summary\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Histogram\n",
    "df['age'].hist(bins=30)\n",
    "plt.title('Age Distribution')\n",
    "\n",
    "# Box plot (shows outliers)\n",
    "sns.boxplot(y=df['age'])\n",
    "\n",
    "# Density plot\n",
    "df['age'].plot(kind='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b48e3",
   "metadata": {},
   "source": [
    "**Categorical Variables**\n",
    "\n",
    "- Frequency Distribution: Count of each category\n",
    "- Cardinality: Number of unique categories \n",
    "- Proportions: Relative frequencies of each category\n",
    "- Find rare categories that may need to be grouped together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eba39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency counts\n",
    "df['category'].value_counts()\n",
    "\n",
    "# Proportions\n",
    "df['category'].value_counts(normalize=True)\n",
    "\n",
    "# Number of unique values\n",
    "df['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298686c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart\n",
    "df['category'].value_counts().plot(kind='bar')\n",
    "\n",
    "# Pie chart (if few categories)\n",
    "df['category'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d558be6",
   "metadata": {},
   "source": [
    "### **Part 3.3: Bivariate Analysis**\n",
    "Analysing the relationship between two variasbles. Generally feature vs target or feature vs feature\n",
    "\n",
    "**Feature vs Target**: Identify which features are potentially predictive of the target variable \n",
    "\n",
    "- Numerical Feature vs Numerical Target: Scatter plots, correlation coefficients (Pearson, Spearman)\n",
    "\n",
    "- Numerical Feature vs Categorical Target: Box plots, violin plots, histograms per category \n",
    "\n",
    "- Categorical vs Categorical Target: Cross tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between two numerical variables\n",
    "plt.scatter(df['age'], df['income'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')\n",
    "\n",
    "# Pearson correlation (-1 to 1)\n",
    "df['age'].corr(df['income'])\n",
    "\n",
    "# Correlation matrix for multiple variables\n",
    "df[['age', 'income', 'credit_score']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776304f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of numerical by category\n",
    "df.groupby('churned')['age'].mean()\n",
    "\n",
    "# Multiple statistics\n",
    "df.groupby('churned')['age'].agg(['mean', 'median', 'std'])\n",
    "\n",
    "# Box plots by group\n",
    "sns.boxplot(x='churned', y='age', data=df)\n",
    "\n",
    "# Violin plots (distribution shape)\n",
    "sns.violinplot(x='churned', y='age', data=df)\n",
    "\n",
    "# Histogram by group\n",
    "df[df['churned']==1]['age'].hist(alpha=0.5, label='Churned')\n",
    "df[df['churned']==0]['age'].hist(alpha=0.5, label='Not Churned')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfada0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency table\n",
    "pd.crosstab(df['gender'], df['churned'])\n",
    "\n",
    "# With percentages\n",
    "pd.crosstab(df['gender'], df['churned'], normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99c34b",
   "metadata": {},
   "source": [
    "**Feature vs Feature**: The important thing here is to check for multicollinearity between features, which can mess up certain models (like linear regression). \n",
    "\n",
    "**High correlation (> 0.8)** between features means they are redundant = consider dropping one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea3fa4",
   "metadata": {},
   "source": [
    "### **Part 3.4: Multivariate Analysis**\n",
    "Analyzing interactions between three or more variables simultaneously to uncover complex relationships and patterns\n",
    "- Use pair plots to visualize relationships between multiple numerical variables\n",
    "- Use 3D scatter plots for three numerical variables\n",
    "- Use heatmaps to visualize correlations among multiple variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ac82f",
   "metadata": {},
   "source": [
    "### **Part 3.5: Distribution Analysis**\n",
    "Analyzing the distribution of key variables to understand their characteristics and inform modeling decisions\n",
    "\n",
    "1. **Check for normality**\n",
    "     - Many algorithms assume normal distribution (e.g., linear regression)\n",
    "     - Use QQ plots and statistical tests (Shapiro-Wilk, Kolmogorov-Smirnov)\n",
    "     - Mean = Median = Mode indicates a gaussian distribution = bell shaped curve\n",
    "\n",
    "2. **Identify skewness and kurtosis**\n",
    "     - Skewed distributions may require transformations (log, square root)\n",
    "     - High kurtosis indicates heavy tails or outliers. Kurtosis > 3 indicates heavy tails = Lots of outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation (for right-skewed)\n",
    "df['log_income'] = np.log1p(df['income'])\n",
    "\n",
    "# Square root\n",
    "df['sqrt_income'] = np.sqrt(df['income'])\n",
    "\n",
    "# Box-Cox transformation\n",
    "from scipy.stats import boxcox\n",
    "df['boxcox_income'], _ = boxcox(df['income'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc67ff",
   "metadata": {},
   "source": [
    "3. **Detect Outliers**\n",
    "\n",
    "     - Use boxplots and IQR method to identify extreme values\n",
    "     - Use z-scores to find points beyond 3 standard deviations from the mean\n",
    "     - Decide whether to cap, remove, or transform outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['age'].quantile(0.25)\n",
    "Q3 = df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['age'] < lower_bound) | (df['age'] > upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1505a8",
   "metadata": {},
   "source": [
    "### **Part 4.2: Dealing with Outliers**\n",
    "\n",
    "There are three broad types of outliers: \n",
    "\n",
    "A. **Data errors:** Entry mistakes, measurement errors\n",
    "Example: Age = 150 years\n",
    "Action: Correct or remove\n",
    "\n",
    "B. **True extreme values:** Valid but rare\n",
    "Example: Luxury home price $10M in dataset of $200K homes\n",
    "Action: Keep or handle carefully\n",
    "\n",
    "C. **Different population:** From different distribution\n",
    "Example: Corporate accounts mixed with individual customers\n",
    "Action: Segment or model separately   \n",
    "\n",
    "There are four strategies to deal with outliers:\n",
    "\n",
    "**A. Remove Outliers: Delete the rows completely**\n",
    "\n",
    "  *When to use:*\n",
    "- Confirmed data errors\n",
    "- Less than 1% of data \n",
    "- Linear models that are sensitive to extremes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e298fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove using IQR\n",
    "df_clean = df[(df['price'] >= lower) & (df['price'] <= upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac83a9",
   "metadata": {},
   "source": [
    "**B. Cap Outliers:** Set extreme values to a maximum/minimum threshold\n",
    "\n",
    "*When to use:*\n",
    "- Outliers are valid but too extreme\n",
    "- Want to keep all data points\n",
    "- Linear models that need bounded ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap at percentiles\n",
    "lower_cap = df['price'].quantile(0.01)\n",
    "upper_cap = df['price'].quantile(0.99)\n",
    "df['price_capped'] = df['price'].clip(lower_cap, upper_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d5ac9",
   "metadata": {},
   "source": [
    "**C. Transform Outliers**: Apply mathematical function to compress range. Reduces impact of extremes without removing information \n",
    "\n",
    "- Log: Strong right skew (most common for money, prices)\n",
    "- Square root: Moderate right skew (counts, areas)\n",
    "- Box-Cox: Automatically finds best transformation\n",
    "\n",
    "*When to use:*\n",
    "\n",
    "- Right-skewed distributions (income, prices, counts)\n",
    "- Outliers are valid and informative\n",
    "- Want to preserve ranking but reduce scale\n",
    "\n",
    "**Note**: Changes interpretation. Now predicting log-price instead of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation (reduces right skew)\n",
    "df['log_price'] = np.log1p(df['price'])\n",
    "\n",
    "# Square root\n",
    "df['sqrt_price'] = np.sqrt(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78bd54",
   "metadata": {},
   "source": [
    "**D. Separate Treatment**: Treat outliers as a different group. You need enough outlier data to model. Example: Build one model for normal customers andone for luxury customers. \n",
    "\n",
    "*When to use:*\n",
    "\n",
    "- Outliers represent fundamentally different behavior\n",
    "- Example: VIP customers, luxury segment, fraud cases\n",
    "- Different patterns require different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag outliers, model separately\n",
    "df['is_outlier'] = (df['price'] > upper) | (df['price'] < lower)\n",
    "\n",
    "# Or create separate model for outliers\n",
    "normal_data = df[df['price'] <= upper]\n",
    "outlier_data = df[df['price'] > upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cf3e5",
   "metadata": {},
   "source": [
    "**Quick Rules:** \n",
    "- Linear models (regression, logistic) are sensitive to outliers, tree models (RF, XGBoost) are not. \n",
    "- For linear models, transform > cap > remove.\n",
    "- If unsure whether removing outliers helps, try training the model with and without outliers and compare test eprformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3848b02",
   "metadata": {},
   "source": [
    "### **Part 4.3: Data Type Correction**\n",
    "\n",
    "Extremely important for proper processing. the first thing to do is to identify the type issues: \n",
    "\n",
    "- Numbers stored as strings? \n",
    "- Dates stored as strings? \n",
    "- Categories stored as objects (unnecessary memory)\n",
    "- Booleans stored a strings (\"true\"/\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6616d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current types\n",
    "df.dtypes\n",
    "\n",
    "# Check unique values (spot type issues)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbada13",
   "metadata": {},
   "source": [
    "**A. Correcting numerical data** \n",
    "- When numbers are stored as text\n",
    "- For example: \"1234\" instead of 1234\n",
    "- Could also be special formats like \"$1,234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to number\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "# errors ='coerce' → invalid values become NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of special formats (\"$1,234\"): Remove $ and commas, then convert\n",
    "df['price'] = df['price'].str.replace('$', '').str.replace(',', '')\n",
    "df['price'] = pd.to_numeric(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ed099",
   "metadata": {},
   "source": [
    "**B. Correct Date/Time Data**\n",
    "- When dates are stored as strings\n",
    "- Use the pd.to_datetime() function \n",
    "- Can also extract useful components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Specify format for speed\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Handle multiple formats\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993edb0",
   "metadata": {},
   "source": [
    "**C. Handle Mixed Types**\n",
    "- When a column has multiple types\n",
    "- Important to handle for correct operations (can't calculate mean of strings)\n",
    "- Feature engineering (can't extract month from string dates)\n",
    "- Model compatibility (algorithms need numeric input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5afab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for mixed types\n",
    "df['mixed_col'].apply(type).value_counts()\n",
    "\n",
    "# Force conversion (lose invalid data)\n",
    "df['clean_col'] = pd.to_numeric(df['mixed_col'], errors='coerce')\n",
    "\n",
    "# Or separate valid/invalid\n",
    "valid = pd.to_numeric(df['mixed_col'], errors='coerce')\n",
    "invalid = df[valid.isnull() & df['mixed_col'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199df7cd",
   "metadata": {},
   "source": [
    "**DECISION FRAMEWORK:**\n",
    "Check dtypes\n",
    "- String numbers → pd.to_numeric()\n",
    "- String dates → pd.to_datetime()\n",
    "- String categories (few unique) → astype('category')\n",
    "- String booleans → map() or astype(bool)\n",
    "- Mixed types → Convert + handle invalids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c75b52",
   "metadata": {},
   "source": [
    "### **Part 4.4. Duplicates Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48fc0c",
   "metadata": {},
   "source": [
    "### **Part 4.5. Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e7202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b442694",
   "metadata": {},
   "source": [
    "### **5.1. Feature Creation**\n",
    "Creating meaningful feastures based on domain knowledge. Think what would be useful in a business context \n",
    "\n",
    "**Step by Step Framework**\n",
    "\n",
    "1. Domain: What makes business sense?\n",
    "2. Time: Any datetime to decompose?\n",
    "3. Aggregations: Can I summarize at customer/store level?\n",
    "4. Ratios: Are relative measures better?\n",
    "5. Flags: Any useful binary conditions?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de504c5f",
   "metadata": {},
   "source": [
    "1. **Domain Based Features**\n",
    "\n",
    "- Use business logic to create meaningful features\n",
    "- Always think about use in a business context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-commerce example\n",
    "df['avg_order_value'] = df['total_spent'] / df['num_orders']\n",
    "df['days_since_last_purchase'] = (today - df['last_purchase_date']).dt.days\n",
    "\n",
    "# Finance example\n",
    "df['debt_to_income_ratio'] = df['total_debt'] / df['annual_income']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a01b2f",
   "metadata": {},
   "source": [
    "2. **Time Based features**: Extract components from datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic components\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Time differences\n",
    "df['days_since_signup'] = (df['current_date'] - df['signup_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4ccf1",
   "metadata": {},
   "source": [
    "3. **Aggregation Features**\n",
    "- Summarize at different levels \n",
    "- Common aggregations: sum, mean, count, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44232496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer-level aggregations from transactions\n",
    "customer_features = transactions.groupby('customer_id').agg({\n",
    "    'amount': ['sum', 'mean', 'count'],\n",
    "    'date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "customer_features.columns = ['customer_id', 'total_spent', 'avg_spent', \n",
    "                              'num_transactions', 'first_purchase', 'last_purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d512c",
   "metadata": {},
   "source": [
    "4. **Ratio Features**: Relative measures could be more useful than absolute ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51effce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratios\n",
    "df['click_through_rate'] = df['clicks'] / df['impressions']\n",
    "df['price_per_sqft'] = df['price'] / df['square_feet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c581f8",
   "metadata": {},
   "source": [
    "5. **Interaction Features**: \n",
    "- Combine features that work together.\n",
    "- Only use when domain knwoledge suggests interaction matters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple multiplications\n",
    "df['bedrooms_x_bathrooms'] = df['bedrooms'] * df['bathrooms']\n",
    "df['total_rooms'] = df['bedrooms'] + df['bathrooms']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc233ba",
   "metadata": {},
   "source": [
    "6. **Boolean/Flag Features**: Binary indicators, usually based on thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold-based\n",
    "df['is_high_value'] = (df['order_value'] > 100).astype(int)\n",
    "df['is_senior'] = (df['age'] >= 65).astype(int)\n",
    "\n",
    "# Missing indicators (can be informative)\n",
    "df['income_missing'] = df['income'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41acf1b5",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- Start with domain knowledge: For churn prediction, I'd create features like:\n",
    "    - days_since_last_login (time-based)\n",
    "    - avg_session_duration (aggregation)\n",
    "    - support_ticket_rate (ratio)\n",
    "    - is_premium_user (flag)\n",
    "\n",
    "- Extract from datetime: Day of week, month, is_weekend, days_since_signup\n",
    "- Create aggregations: Total spend, average order value, number of transactions per customer\n",
    "- Build ratios: Revenue per employee, clicks per impression\n",
    "\n",
    "- **Key principle: Start simple with domain features, add complexity only if improves performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d3290",
   "metadata": {},
   "source": [
    "### **5.2. Feature Transformation**\n",
    "\n",
    "Transforming skewed features helps improve model performance \n",
    "\n",
    "**1. Identify Need**\n",
    "- Check skewness\n",
    "- Transform when skewness > 1 (right skewed)\n",
    "- Especially relevant for linear models\n",
    "- Income, prices, population all tend to be right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness\n",
    "from scipy.stats import skew\n",
    "skewness = df['income'].skew()\n",
    "print(f\"Skewness: {skewness}\")  # |skew| > 1 suggests transformation\n",
    "\n",
    "# Visual check\n",
    "df['income'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b381c",
   "metadata": {},
   "source": [
    "**2. Apply Log Transformation**\n",
    "- Compresses large values more than small values \n",
    "- Use when strong right skew (skewness > 1)\n",
    "- Linear models benfit most, tree models often dont need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For right-skewed data (income, prices, counts)\n",
    "df['log_income'] = np.log1p(df['income'])  # log1p handles zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197e679",
   "metadata": {},
   "source": [
    "**3. Validate:** Goal is to get skewness closer to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check improvement\n",
    "print(f\"Original skew: {df['income'].skew():.2f}\")\n",
    "print(f\"Transformed skew: {df['log_income'].skew():.2f}\")\n",
    "\n",
    "# Visualize before/after\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "df['income'].hist(bins=50, ax=axes[0], title='Original')\n",
    "df['log_income'].hist(bins=50, ax=axes[1], title='Log Transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57554273",
   "metadata": {},
   "source": [
    "4. **Fit ONLY on training data**: Fit transformer on training data only, then apply to test data with same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "transformer = PowerTransformer()  # Yeo-Johnson (handles negatives)\n",
    "\n",
    "# Fit on train, apply to test\n",
    "train['transformed'] = transformer.fit_transform(train[['income']])\n",
    "test['transformed'] = transformer.transform(test[['income']])  # Use train params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f260852",
   "metadata": {},
   "source": [
    "### **5.3. Encoding Categorical Variables**\n",
    "\n",
    "ML algorithms need numerical inpout so it is important to encode categorical variables \n",
    "\n",
    "1. **Understand your variable type**\n",
    "\n",
    "- Nominal = No order (e.g. city, color, etc)\n",
    "- Ordinal = Has some order (e.g. ratings)\n",
    "\n",
    "2. **One Hot Encoding**\n",
    "- For linear models, required for nominal variables\n",
    "- Creates a binary column for each category \n",
    "- Use when there's low cardinality (<20 categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9742960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "encoded = ohe.fit_transform(df[['city']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116226d6",
   "metadata": {},
   "source": [
    "3. **Label Encoding**\n",
    "\n",
    "- Assigns an integer to each category \n",
    "- Tree based models: Works for nominal and ordinal \n",
    "- Works with ordinal variables for any model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['city_encoded'] = le.fit_transform(df['city'])\n",
    "\n",
    "# NYC → 0, LA → 1, Chicago → 2\n",
    "\n",
    "# Education has meaningful order\n",
    "education_map = {'High School': 0, 'Bachelor': 1, 'Master': 2, 'PhD': 3}\n",
    "df['education_encoded'] = df['education'].map(education_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a9727",
   "metadata": {},
   "source": [
    "4. **Handling High Cardinality**\n",
    "\n",
    "- Problem: 500 cities → 500 one-hot columns (too many!)\n",
    "- Solution: Group rare categories as \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48dd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep top 10 categories, rest → \"Other\"\n",
    "top_categories = df['city'].value_counts().head(10).index\n",
    "\n",
    "df['city_grouped'] = df['city'].apply(\n",
    "    lambda x: x if x in top_categories else 'Other'\n",
    ")\n",
    "\n",
    "# Now one-hot encode (only 10-11 columns)\n",
    "df_encoded = pd.get_dummies(df, columns=['city_grouped'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68cecf",
   "metadata": {},
   "source": [
    "5. **Handling unknown categories:** Test set might have categories we have not seen in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9dc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot: use handle_unknown='ignore'\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')  # Creates all-zero row\n",
    "\n",
    "# Label Encoding: map with default\n",
    "city_map = {'NYC': 0, 'LA': 1, 'Chicago': 2}\n",
    "test['city_encoded'] = test['city'].map(city_map).fillna(-1)  # -1 for unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebbbfe",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "**Linear models:**\n",
    "- Nominal variables → One-Hot encoding (required)\n",
    "- `pd.get_dummies(df, columns=['city'], drop_first=True)`\n",
    "\n",
    "**Tree models:**\n",
    "- Can use Label Encoding (simpler, efficient)\n",
    "- `LabelEncoder().fit_transform(df['city'])`\n",
    "\n",
    "**Ordinal variables (any model):** Label encode with proper order\n",
    "\n",
    "**High cardinality:**\n",
    "- Group rare categories into 'Other' (keep top 10-20)\n",
    "- Then one-hot encode\n",
    "\n",
    "**Key:** Always fit on training data, apply to test with same mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f1a77",
   "metadata": {},
   "source": [
    "### **5.4. Feature Scaling**\n",
    "\n",
    "It is important to scale features so that they are on similar ranges. \n",
    "\n",
    "*Example*: \n",
    "- age: 20-80 (range of 60)\n",
    "- income: 20,000-200,000 (range of 180,000)\n",
    "- Without scaling, income dominates distance calculations\n",
    "\n",
    "**1. Check algorithm**\n",
    "- Distance based algorithms need scaling (Linear, logistic, KNN, SVM)\n",
    "- Tree based models do not need scaling (RF, XGBoost, Decision Trees)\n",
    "\n",
    "**2. StandardScaler()**\n",
    "- What it does: Mean = 0 and Std = 1\n",
    "- Most common scaler\n",
    "- **Formula:** `(x - mean) / std`\n",
    "\n",
    "- **Result:** Features centered around 0, most values between -3 and 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c90fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on train, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use train mean/std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4434f05",
   "metadata": {},
   "source": [
    "**3. MinMaxScaler()**\n",
    "- Scales to range [0, 1]\n",
    "- Use when you need abounded range (eg for neural networks)\n",
    "- Useful when you don't want negative values\n",
    "- Limitation: Sensitive to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22742c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0638c",
   "metadata": {},
   "source": [
    "4. **RobustScaler()**\n",
    "\n",
    "- Useful to deal with outliers\n",
    "- Uses median and IQR\n",
    "- **Formula:** `(x - median) / IQR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf573004",
   "metadata": {},
   "source": [
    "**Scale:**\n",
    "- Numerical features with different units/ranges\n",
    "\n",
    "**Don't scale:**\n",
    "- Binary features (0/1) - already same scale\n",
    "- One-hot encoded features - already 0/1\n",
    "- Tree-based models - not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0464c5",
   "metadata": {},
   "source": [
    "**Check if needed:**\n",
    "- **Tree models:** Don't need scaling\n",
    "- **Linear models with regularization:** Need scaling (regularization penalizes by coefficient size)\n",
    "- **Distance-based (KNN, SVM):** Need scaling (distances dominated by large-scale features)\n",
    "\n",
    "**Choose scaler:**\n",
    "- **StandardScaler (default):** Centers at mean=0, std=1\n",
    "- **RobustScaler:** If outliers present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENT SCALER USING PIPELINE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)  # Fits scaler on train only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423dec0",
   "metadata": {},
   "source": [
    "### **5.5. Feature Selection**\n",
    "\n",
    "Select relevant features to improve performance and reduce overfitting\n",
    "\n",
    "**Benefits:**\n",
    "- Reduces overfitting\n",
    "- Faster training\n",
    "- Simpler, more interpretable models\n",
    "- Removes irrelevant/redundant features\n",
    "\n",
    "**When needed:**\n",
    "- Many features (100+)\n",
    "- Some features irrelevant\n",
    "- Model overfitting\n",
    "\n",
    "1. **Remove low variance features**\n",
    "- Remove features with low variation\n",
    "- Features that are almost constant add no information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470105b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove features with <1% variance\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_selected = selector.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cde73e0",
   "metadata": {},
   "source": [
    "2. **Remove highly correlated features:** Highly correlated features are redundant (multicollinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Find pairs with correlation > 0.9\n",
    "upper_tri = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "# Drop one from each highly correlated pair\n",
    "to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.9)]\n",
    "X_selected = X_train.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376299af",
   "metadata": {},
   "source": [
    "3. **Select based on Importance:** Use feature importance from tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Keep top N features\n",
    "top_features = importance.head(20)['feature'].tolist()\n",
    "X_selected = X_train[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531b00b",
   "metadata": {},
   "source": [
    "4. **L1 Regularization (LASSO)**: Automatically zeros out unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Lasso with cross-validation\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Keep non-zero coefficients\n",
    "selected_features = X_train.columns[lasso.coef_ != 0]\n",
    "X_selected = X_train[selected_features]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} out of {len(X_train.columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11ea80",
   "metadata": {},
   "source": [
    "5. **Dimensionality Reduction (PCA)**: Combine correlated features into fewer components \n",
    "\n",
    "   **When to use:**\n",
    "- Many correlated features\n",
    "- Want to reduce dimensions\n",
    "- Less interpretable (components are combinations)\n",
    "\n",
    "- **Trade-off:** Lose interpretability (can't say \"age matters\" - only \"PC1 matters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 10 components (or explain 95% variance)\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"Reduced from {X_train.shape[1]} to {X_pca.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815ff08",
   "metadata": {},
   "source": [
    "6. **Forward/Backward Selection**\n",
    "- Iteratively add/removefeatures\n",
    "- Slow for many features, so use only for small feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbdc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified forward selection concept\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    LogisticRegression(),\n",
    "    n_features_to_select=10,  # Select best 10\n",
    "    direction='forward',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "sfs.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec374097",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "**Step 1 - Remove obvious issues:**\n",
    "- Low-variance features (almost constant)\n",
    "- Highly correlated features (keep one from each pair with r > 0.9)\n",
    "\n",
    "**Step 2 - Model-based selection:**\n",
    "- **Tree models:** Use `feature_importances_`, keep top N features\n",
    "- **Linear models:** Use Lasso, keeps non-zero coefficients\n",
    "\n",
    "**Step 3 - Validate:**\n",
    "- Train model with selected features\n",
    "- Compare performance to using all features\n",
    "- Ideally: similar performance with fewer features\n",
    "\n",
    "**PCA:** Reduces dimensions by combining correlated features. Good for visualization or when many correlated features, but loses interpretability.\n",
    "\n",
    "**Key principle:** Start with all features, remove if not helping performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1708fc1",
   "metadata": {},
   "source": [
    "### **6. Data Splitting**\n",
    "\n",
    "Important to split data in order to ensure valid model evaluation \n",
    "\n",
    "1. **Train/Validation/Split**\n",
    "\n",
    "- Train (60%): Fit model parameters\n",
    "- Validation (20%): Tune hyperparameters, compare models\n",
    "- Test (20%): Final evaluation (touch ONCE at end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ba6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: train+val vs test (80/20)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: train vs val (75/25 of remaining = 60/20 overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Final split: 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce508dc3",
   "metadata": {},
   "source": [
    "2. **Stratified Split**\n",
    "- Maintain class proportions in each split\n",
    "- Used for classification\n",
    "\n",
    "   When to Use: \n",
    "   - Imbalanced Classes\n",
    "   - Small datasets\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imbalanced data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,  # Maintains class proportions\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# If 80/20 class split in full data → 80/20 in train AND test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e7b18",
   "metadata": {},
   "source": [
    "3. **Cross Validation**\n",
    "- K-Fold CV: Split into K folds, train K times\n",
    "- Split data into 5 parts (or k parts)\n",
    "- Train on 4, validate on 1\n",
    "- Repeat 5 times (each fold used for validation once)\n",
    "- Average results\n",
    "\n",
    "   When to Use: \n",
    "   - Small datasets (maximizes training data)\n",
    "   - Robust performance estimate\n",
    "   - Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 5-fold cross-validation\n",
    "scores = cross_val_score(\n",
    "    model, X_train, y_train, \n",
    "    cv=5,  # 5 folds\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "print(f\"CV scores: {scores}\")\n",
    "print(f\"Mean AUC: {scores.mean():.3f} (+/- {scores.std():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829edc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stratified K fold for classification\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train_fold = X.iloc[train_idx]\n",
    "    X_val_fold = X.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21e404",
   "metadata": {},
   "source": [
    "4. **Time Series Split**: \n",
    "- Never shuffle, maintain order\n",
    "- Always train on the past, predict future: no data leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_idx, val_idx in tscv.split(X):\n",
    "    X_train = X.iloc[train_idx]\n",
    "    X_val = X.iloc[val_idx]\n",
    "    # Train on past, validate on future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ec1ac",
   "metadata": {},
   "source": [
    "**Small Dataset (less than 1k samples):** Use cross validation, no separate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4bfc7b",
   "metadata": {},
   "source": [
    "**Medium dataset (1K-100K)**: Use 80/20 train/test + 5-fold CV on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a68742",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9c3f7",
   "metadata": {},
   "source": [
    "**Large dataset (>100K):** Simple train/val/test split (60/20/20). CV too slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26468d",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "Standard approach:\n",
    "- 60% train, 20% validation, 20% test\n",
    "- Or 80/20 train/test + 5-fold CV on train\n",
    "\n",
    "Classification: Use stratify = y to maintain class proportions\n",
    "\n",
    "Time-series:\n",
    "- Never shuffle! Use TimeSeriesSplit\n",
    "- Train on past, validate on future\n",
    "\n",
    "Prevent leakage:\n",
    "- Fit all preprocessing (scaling, encoding) on training data only\n",
    "- Use sklearn Pipeline to automate this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7fa73",
   "metadata": {},
   "source": [
    "### **7.1. Baseline Model**\n",
    "\n",
    "This is the simplest possible model that sets a minumum performance bar to show if complex models actually add value. \n",
    "If your model is not ablke to ebat the baseline, then something is wrong...\n",
    "\n",
    "**For classification**: Predict the most frequent class. Example: If 80% of customers don't churn, predicting \"no churn\" for everyone gives 80% accuracy baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c86272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Strategy 1: Predict most frequent class\n",
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_score = baseline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Baseline accuracy: {baseline_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed52b3d",
   "metadata": {},
   "source": [
    "**For Regression**: The baseline can either be the mean or the median. Baseline tells you: \n",
    "- R² = 0 for mean prediction → any model should have R² > 0\n",
    "- RMSE of mean prediction → target to beat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c028cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# Strategy 1: Predict mean\n",
    "baseline = DummyRegressor(strategy='mean')\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_score = baseline.score(X_test, y_test)  # R²\n",
    "\n",
    "# Strategy 2: Predict median (robust to outliers)\n",
    "baseline = DummyRegressor(strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ba2c0",
   "metadata": {},
   "source": [
    "### **Part 7.2.1. Linear Regression**\n",
    "\n",
    "Finds the best-fit straight line through data points. Starting point for regression problems because it is simple, iterpretable and fast. \n",
    "\n",
    "The model predicts: **y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε**\n",
    "\n",
    "- **y:** Target (what we predict)\n",
    "- **β₀:** Intercept (baseline value)\n",
    "- **β₁, β₂, ...:** Coefficients (impact of each feature)\n",
    "- **x₁, x₂, ...:** Features\n",
    "- **ε:** Error term\n",
    "\n",
    "**Example:** House price = 50,000 + 100×(square_feet) + 5,000×(bedrooms)\n",
    "\n",
    "**How it learns:** Minimize the sum of squared errors (least squares)\n",
    "\n",
    "Loss = Σ(actual - predicted)²\n",
    "\n",
    "**Objective**: Draw a line that minimises this loss, ie the vertical distance to each point \n",
    "\n",
    "**Good For:** \n",
    "- Linear relationships between features and target\n",
    "- Need interpretability (can explain: \"each bedroom adds $5K\")\n",
    "- Fast training needed\n",
    "- Baseline model\n",
    "- Small datasets\n",
    "\n",
    "**Struggles with:**\n",
    "- Non-linear relationships\n",
    "- Multicollinearity (highly correlated features)\n",
    "- Many outliers (sensitive to them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc128f5",
   "metadata": {},
   "source": [
    "**The 5 Key Assumptions**\n",
    "\n",
    "A. Linearity: Relationship between X and Y is linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb34b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: scatter plots\n",
    "plt.scatter(X['feature'], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c208b7b2",
   "metadata": {},
   "source": [
    "B. Independence: Observations are independent (not time-series with autocorrelation)\n",
    "\n",
    "C. Homoscedasticity: Constant variance of errors, scatter of errors looks like random cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae24efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: residual plot (should be random cloud)\n",
    "residuals = y_true - y_pred\n",
    "plt.scatter(y_pred, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce684315",
   "metadata": {},
   "source": [
    "D. Normality of errors: Residuals are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0208578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377e431",
   "metadata": {},
   "source": [
    "E. No multicollinearity: Features not highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: correlation matrix\n",
    "corr_matrix = X.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd3b01",
   "metadata": {},
   "source": [
    "There are no hyperparameters for linear regression. The only parameter is fit_intercept\n",
    "\n",
    "- fit_intercept=True: Estimate β₀ (usual case)\n",
    "- fit_intercept=False: Force line through origin (rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1b8ef",
   "metadata": {},
   "source": [
    "\n",
    "**Limitations**\n",
    "\n",
    "**A. Sensitive to outliers:**\n",
    "- One extreme point can skew entire line\n",
    "- Solution: Remove outliers or use robust methods\n",
    "\n",
    "**B. Assumes linearity:**\n",
    "- Can't capture curves/interactions naturally\n",
    "- Solution: Feature engineering (polynomials, interactions)\n",
    "\n",
    "**C. Multicollinearity problems:**\n",
    "- Unstable coefficients when features correlated\n",
    "- Solution: Ridge/Lasso regression\n",
    "\n",
    "**D. No automatic feature selection:**\n",
    "- Uses all features (even irrelevant ones)\n",
    "- Solution: Lasso regression or manual selection\n",
    "\n",
    "**E. Extrapolation risk:**\n",
    "- Predictions outside training range unreliable\n",
    "- Example: Trained on $100K-$500K houses, predicting $2M house is risky\n",
    "\n",
    "**Summing Up:** \n",
    "\n",
    "- Pros: Fast, interpretable (can explain each coefficient's impact), works well for linear relationships, no hyperparameters to tune.\n",
    "\n",
    "- Checks: I'd verify assumptions - linearity via scatter plots, multicollinearity via correlation matrix, homoscedasticity via residual plots.\n",
    "\n",
    "- If assumptions violated: Consider polynomial features for non-linearity, Ridge/Lasso for multicollinearity, or switch to tree-based models for complex non-linear patterns.\n",
    "\n",
    "- Expected performance: If R² > 0.7 and assumptions hold, Linear Regression is often sufficient. If R² < 0.5, likely need more complex models or better features\n",
    "\n",
    "**Comparison Table**\n",
    "\n",
    "\n",
    "| Aspect | Linear Regression | Decision Tree | Random Forest |\n",
    "|--------|------------------|---------------|---------------|\n",
    "| Interpretability | ✅ Very high | ✅ High | ❌ Low |\n",
    "| Speed | ✅ Very fast | ✅ Fast | ⚠️ Slower |\n",
    "| Handles non-linearity | ❌ No | ✅ Yes | ✅ Yes |\n",
    "| Handles outliers | ❌ No | ✅ Yes | ✅ Yes |\n",
    "| Feature scaling needed | ✅ Yes | ❌ No | ❌ No |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL IMPLEMENTATION OF LINEAR REGRESSION \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': model.coef_\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(coefficients)\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed1cb0",
   "metadata": {},
   "source": [
    "### **7.2.2. Logistic Regression**\n",
    "\n",
    "Predict **probability** that something belongs to a class (0 or 1). Fast, interpretable and gives probabilities for binary classification\n",
    "\n",
    "The **sigmoid function** squashes any number into the range [0, 1]. It is an S-shaped curve. \n",
    "\n",
    "**p(y=1) = 1 / (1 + e^-(β₀ + β₁x₁ + β₂x₂ + ...))**\n",
    "\n",
    "- Large negative → probability near 0\n",
    "- Large positive → probability near 1\n",
    "- Zero → probability = 0.5\n",
    "\n",
    "\n",
    "**How it learns:** It Maximizes likelihood. Find coefficients that make observed outcomes most probable.\n",
    "\n",
    "**Good for:**\n",
    "\n",
    "- Binary classification (yes/no, 0/1)\n",
    "- Need probability estimates (not just class labels)\n",
    "- Need interpretability (coefficients show feature impact)\n",
    "- Linear decision boundary acceptable\n",
    "- Baseline classification model\n",
    "- Class imbalance moderate (<90/10 split)\n",
    "\n",
    "**Not good for:**\n",
    "\n",
    "- Multi-class (use multinomial logistic or other methods)\n",
    "- Highly non-linear decision boundaries\n",
    "- Features not linearly separable\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "A. Linear relationship between features and log-odds:\n",
    "\n",
    "- Log-odds = β₀ + β₁x₁ + ...\n",
    "- Check with scatter plots of features vs. log-odds\n",
    "\n",
    "B. Independence of observations: Each data point independent\n",
    "\n",
    "C. No multicollinearity: Features shouldn't be highly correlated\n",
    "\n",
    "D. Large sample size: Need enough data (rule of thumb: 10-15 events per feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b68a95",
   "metadata": {},
   "source": [
    "**Hyperparameters**\n",
    "\n",
    "A. **C: Regularization Strength**\n",
    "\n",
    "- Confidence in training data. \n",
    "- Defeault C = 1.  \n",
    "- High C (e.g., 100): \"Trust the training data more\" → Complex model, fits training closely, risk overfitting\n",
    "- Low C (e.g., 0.01): \"Keep it simple\" → Simpler model, ignores noise, risk underfitting\n",
    "\n",
    "B. **L1 vs L2: Penalty**\n",
    "\n",
    "- L2 (Ridge): \"Shrink all features a little\" → Keeps all features but reduces their impact\n",
    "- L1 (Lasso): \"Remove useless features\" → Sets some coefficients to exactly zero (feature selection)\n",
    "- elasticnet: Mix of l1 and l2\n",
    "- none: No regularisation - Only use iff there is no overfitting \n",
    "\n",
    "C. **class_weight (for imbalanced data):**\n",
    "\n",
    "- None (default): Equal weight to all classes\n",
    "- 'balanced': Automatically adjusts weights inversely proportional to class frequency\n",
    "- Custom dict: {0: 1, 1: 10} → penalize class 1 errors 10x more\n",
    "\n",
    "D. **solver:**\n",
    "\n",
    "- Different algorithms to find the coefficients\n",
    "- 'lbfgs' (default): Good for most cases, works with l2\n",
    "- 'liblinear': Good for small datasets, works with l1\n",
    "- 'saga': Works with all penalties, good for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09549b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING USING GRIDSEARCHCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best AUC: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Use best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3631f78",
   "metadata": {},
   "source": [
    "**Imbalanced classes: One class has way more examples than the other.**\n",
    "\n",
    "Examples:\n",
    "- Fraud detection: 99% legitimate, 1% fraud\n",
    "- Churn: 80% stay, 20% leave\n",
    "- Disease screening: 95% healthy, 5% sick\n",
    "\n",
    "Problem: Model learns to just predict majority class (gets 99% accuracy by always saying \"not fraud\")\n",
    "- Balanced: 50/50 or 60/40 split\n",
    "- Imbalanced: >70/30 split\n",
    "- Severe imbalance: >90/10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02078517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEALING WITH IMBALANCED CLASSES\n",
    "\n",
    "# Method 1: class_weight='balanced'\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Method 2: Custom weights\n",
    "weights = {0: 1, 1: 5}  # Penalize minority class errors 5x more\n",
    "model = LogisticRegression(class_weight=weights)\n",
    "\n",
    "# Method 3: Adjust threshold\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_custom = (y_proba > 0.3).astype(int)  # Lower threshold to catch more positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea976ab",
   "metadata": {},
   "source": [
    "**Limitations**\n",
    "\n",
    "A. **Assumes linear decision boundary:**\n",
    "\n",
    "- Can't naturally capture complex non-linear patterns\n",
    "- Solution: Feature engineering (polynomial features, interactions)\n",
    "\n",
    "B. **Sensitive to outliers:**\n",
    "\n",
    "- Extreme values can influence coefficients\n",
    "- Solution: Remove outliers or use robust scaling\n",
    "\n",
    "C. **Requires feature scaling:**\n",
    "\n",
    "- Features on different scales affect regularization unevenly\n",
    "- Solution: Standardize features before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954218f",
   "metadata": {},
   "source": [
    "D. **Poor with high-dimensional sparse data**:\n",
    "\n",
    "- Many features relative to samples\n",
    "- Solution: L1 regularization or feature selection\n",
    "\n",
    "E. **Limited to linear separability:**\n",
    "\n",
    "- If classes not linearly separable, performance suffers\n",
    "- Solution: Try SVM with kernel or tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e9b6b",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Outputs probabilities (can rank customers by risk)\n",
    "- Interpretable coefficients (show feature impact)\n",
    "- Fast training and prediction\n",
    "- Handles moderate imbalance with class_weight='balanced'\n",
    "\n",
    "Hyperparameters to tune:\n",
    "\n",
    "- C (regularization strength): Try [0.01, 0.1, 1, 10]\n",
    "- penalty: L1 for feature selection, L2 if all features useful\n",
    "- class_weight: 'balanced' if classes imbalanced\n",
    "\n",
    "Feature prep:\n",
    "\n",
    "- Scale features (StandardScaler) before training\n",
    "- Check for multicollinearity (correlation >0.8)\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "- Use AUC-ROC (threshold-independent)\n",
    "- Precision-Recall curve if imbalanced\n",
    "- Calibration plot to verify probability quality\n",
    "\n",
    "**When to switch: If AUC < 0.7 or clear non-linear patterns, try tree-based models or add polynomial features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL IMPLEMENTATION OF LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd55c3b",
   "metadata": {},
   "source": [
    "### **7.3.1: Decision Trees**\n",
    "\n",
    "Intuitive interpretable models that make predictions by learning simple decision rules from data. Split data into branches based on feature values, like a flowchart. \n",
    "\n",
    "                     Age > 30?               \n",
    "                   /          \\               \n",
    "                 Yes           No              \n",
    "                 /              \\           \n",
    "        Income > 50K?      Student?              \n",
    "         /        \\         /      \\          \n",
    "       Yes        No      Yes      No          \n",
    "        |          |       |        |         \n",
    "      Buy      Don't   Don't      Buy          \n",
    "\n",
    "\n",
    "**How it learns:** \n",
    "1. Find best feature and split point that separates classes best\n",
    "2. Repeat for each branch recursively\n",
    "3. Stop when pure (all same class) or max depth reached\n",
    "\n",
    "**Mathematical intuition:**\n",
    "\n",
    "At each split, find feature and threshold that maximizes:\n",
    "- **Classification:** Information Gain (or Gini decrease)\n",
    "- **Regression:** Variance reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67e331",
   "metadata": {},
   "source": [
    "**Hyperparameters to Tune**\n",
    "\n",
    "**A. max_depth:**\n",
    "\n",
    "- None (default): Grow until pure leaves → OVERFITS\n",
    "- Small (3-5): Shallow tree, simple model, may underfit\n",
    "- Medium (5-10): Good balance\n",
    "- Large (>15): Deep tree, complex, likely overfits\n",
    "\n",
    "**Intuition:** How many questions can you ask?\n",
    "\n",
    "- max_depth=3 → 3 questions maximum\n",
    "- Deeper = more complex patterns, more overfitting risk\n",
    "\n",
    "Typical range: [3, 5, 7, 10, 15, 20, None]\n",
    "\n",
    "**B. min_samples_split:**\n",
    "\n",
    "- Default: 2 → Split if ≥2 samples\n",
    "- Higher (20, 50): More samples needed to split → simpler tree\n",
    "\n",
    "**Intuition:** Don't split unless you have enough data\n",
    "\n",
    "- min_samples_split=50 → need 50 samples before considering a split\n",
    "- Typical range: [2, 10, 20, 50, 100]\n",
    "\n",
    "**C. min_samples_leaf:**\n",
    "\n",
    "Default: 1 → Leaves can have 1 sample → OVERFITS\n",
    "Higher (5, 10, 20): Each leaf needs more samples → simpler tree\n",
    "\n",
    "Intuition: Don't trust tiny leaves\n",
    "\n",
    "min_samples_leaf=10 → every prediction based on ≥10 samples\n",
    "\n",
    "Typical range: [1, 5, 10, 20, 50]\n",
    "\n",
    "**D. max_features:**\n",
    "\n",
    "None: Consider all features at each split\n",
    "'sqrt': Consider √(n_features) random features\n",
    "'log2': Consider log₂(n_features) features\n",
    "int: Specific number\n",
    "\n",
    "Intuition: Adds randomness, reduces overfitting\n",
    "\n",
    "Often used in Random Forest, less critical for single tree\n",
    "\n",
    "**E. class_weight (for classification):**\n",
    "\n",
    "None: Equal weight\n",
    "'balanced': Adjust weights for imbalanced classes\n",
    "Dict: Custom weights\n",
    "\n",
    "Same concept as Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdaf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Use best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2ed46",
   "metadata": {},
   "source": [
    "**Overfitting Issue**: Decision trees overfit very easily \n",
    "\n",
    "- With no constraints, tree memorizes training data\n",
    "- Creates one leaf per training sample\n",
    "- Perfect training accuracy, poor test accuracy\n",
    "\n",
    "Therefor it is important to ALWAYS limit tree growth through **pruning** strategies\n",
    "\n",
    "**A. Pre-pruning = Stop growing early** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier (\n",
    "    max_depth=5,              # Limit depth\n",
    "    min_samples_split=20,     # Need 20+ samples to split\n",
    "    min_samples_leaf=10       # Leaves need 10+ samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19817c",
   "metadata": {},
   "source": [
    "**B. Post-pruning = grow full, then cut backwards**\n",
    "\n",
    "Higher the ccp_alpha = More aggressive pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(ccp_alpha=0.01)  # Cost-complexity pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f81b2",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "1. No feature scaling needed\n",
    "2. Handles non-linearity automatically: Captures thresholds and curves naturally\n",
    "3. Handles mixed data types: Can mix numerical and categorical (after encoding)\n",
    "4. Robust to outliers: Splits based on ranking \n",
    "5. Highly interpretable: Can visualise entire decision path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afc170",
   "metadata": {},
   "source": [
    "**Limitations**\n",
    "\n",
    "**A. Instability:**\n",
    "\n",
    "- Small data changes → completely different tree\n",
    "- Not robust\n",
    "-  Solution = Use random forest (ensemble of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28130f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on slightly different data\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train[:-10], y_train[:-10])  # Remove 10 samples\n",
    "# Trees can look totally different!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c72f7a",
   "metadata": {},
   "source": [
    "**B. Overfitting tendency:**\n",
    "\n",
    "- Without constraints, memorizes training data\n",
    "- Solution: ALWAYS tune max_depth, min_samples_leaf\n",
    "\n",
    "**C. Biased toward features with more levels:**\n",
    "\n",
    "- Features with more unique values favored in splits\n",
    "- Solution: Use Random Forest or limit max_features\n",
    "\n",
    "**D. Cannot Extrapolate**\n",
    "\n",
    "- Trained on ages 18-65\n",
    "- Predicting age 80 → uses closest leaf (age 65)\n",
    "- Can't predict beyond training range\n",
    "\n",
    "**E. Creates axis-parallel splits:**\n",
    "- Only splits on one feature at a time\n",
    "- Can't capture diagonal decision boundaries naturally\n",
    "- **Solution:** Feature engineering (create interaction features)\n",
    "\n",
    "\n",
    "**F. Biased with imbalanced classes:**\n",
    "- Prefers majority class\n",
    "- **Solution:** class_weight='balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf90aa7",
   "metadata": {},
   "source": [
    "\n",
    "| Aspect | Decision Tree | Linear Regression | Logistic Regression |\n",
    "|--------|---------------|-------------------|---------------------|\n",
    "| **Non-linearity** | ✅ Handles naturally | ❌ Needs feature engineering | ❌ Needs feature engineering |\n",
    "| **Interpretability** | ✅ Visual tree | ✅ Coefficients | ✅ Coefficients |\n",
    "| **Feature scaling** | ✅ Not needed | ❌ Required | ❌ Required |\n",
    "| **Outliers** | ✅ Robust | ❌ Sensitive | ❌ Sensitive |\n",
    "| **Overfitting risk** | ⚠️ High (needs tuning) | ⚠️ Medium | ⚠️ Medium |\n",
    "| **Stability** | ❌ Unstable | ✅ Stable | ✅ Stable |\n",
    "| **Speed** | ✅ Fast | ✅ Very fast | ✅ Very fast |\n",
    "\n",
    "\n",
    "**Advantages for this problem:**\n",
    "\n",
    "- Handles non-linear patterns naturally [if applicable]\n",
    "- No feature scaling needed\n",
    "- Interpretable - can visualize decision rules\n",
    "- Robust to outliers\n",
    "- Captures feature interactions automatically\n",
    "\n",
    "**Critical: Prevent overfitting:**\n",
    "\n",
    "- Tune max_depth (start with 5-10)\n",
    "- Set min_samples_leaf (10-20 for reasonable leaf size)\n",
    "- Use cross-validation to find optimal hyperparameters\n",
    "\n",
    "**Hyperparameter strategy:**\n",
    "\n",
    "- Grid search over max_depth=[3,5,7,10], min_samples_leaf=[5,10,20]\n",
    "- Monitor train vs test accuracy gap\n",
    "- If large gap → more regularization (lower max_depth, higher min_samples_leaf)\n",
    "\n",
    "**When to switch:**\n",
    "\n",
    "- If single tree unstable → Random Forest\n",
    "- If need higher performance → Gradient Boosting (XGBoost)\n",
    "- If smooth linear relationship → Ridge/Lasso\n",
    "\n",
    "**Expected outcome:** Decision tree should capture non-linear patterns that linear models miss, but single tree may overfit - Random Forest likely better choice for production.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f81e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTATION FOR CLASSIFICATION\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train (limiting depth to prevent overfitting)\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTATION FOR REGRESSION\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = DecisionTreeRegressor(\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9622f62",
   "metadata": {},
   "source": [
    "### **7.3.2. Random Forest**\n",
    "\n",
    "Train many decision trees on random subsets of data, then average their predictions. It has 3 main steps: \n",
    "\n",
    "A. **Bootstrap Sampling (Bagging)**:\n",
    "\n",
    "- Create N different training sets by **random sampling with replacement**\n",
    "- Each tree trained on different subset\n",
    "- Typical: each subset = same size as original, but with duplicates\n",
    "\n",
    "*Example*: Original data = [1,2,3,4,5]\n",
    "\n",
    "- Tree 1 trained on: [1,1,3,4,5]\n",
    "- Tree 2 trained on: [2,2,3,3,4]\n",
    "- Tree 3 trained on: [1,2,5,5,5]\n",
    "\n",
    "B. **Random Feature Selection**:\n",
    "\n",
    "- At each split, only consider random subset of features\n",
    "- Typical: √(n_features) for classification, n_features/3 for regression\n",
    "- Makes trees more diverse (decorrelated)\n",
    "\n",
    "*Example*: 10 features total\n",
    "\n",
    "- Split 1: randomly consider features [2, 5, 8]\n",
    "- Split 2: randomly consider features [1, 3, 9]\n",
    "\n",
    "C. **Aggregate Predictions:**\n",
    "\n",
    "- Classification: Majority vote\n",
    "- Regression: Average\n",
    "\n",
    "*Example* - Classification:\n",
    "\n",
    "- Tree 1 predicts: Class 1\n",
    "- Tree 2 predicts: Class 0\n",
    "- Tree 3 predicts: Class 1\n",
    "- **Final prediction: Class 1 (2 out of 3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab25e2",
   "metadata": {},
   "source": [
    "**Overcoming the Bias-Variance Tradeoff:**\n",
    "\n",
    "Single Decision Tree:\n",
    "\n",
    "- Low bias (can fit complex patterns)\n",
    "- HIGH variance (unstable, changes with data)\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "- Low bias (still flexible)\n",
    "- LOW variance (averaging reduces instability)\n",
    "\n",
    "Intuition:\n",
    "\n",
    "- Individual trees make different mistakes\n",
    "- Averaging cancels out random errors\n",
    "- Only systematic patterns survive\n",
    "\n",
    "Mathematical: Variance of average of N uncorrelated models = Variance/N \n",
    "\n",
    "\n",
    "**Good For**\n",
    "\n",
    "- Almost any tabular data problem (very general-purpose)\n",
    "- Non-linear relationships\n",
    "- Feature interactions\n",
    "- Outliers present\n",
    "- Need feature importance\n",
    "- Imbalanced classes\n",
    "- High-dimensional data\n",
    "- When single decision tree overfits\n",
    "- Need robust, stable predictions\n",
    "\n",
    "**Not good for:**\n",
    "\n",
    "- High-cardinality categorical features (many unique values)\n",
    "- Very large datasets (slower than single tree)\n",
    "- Need simple interpretability (can't visualize like single tree)\n",
    "- Linear relationships (overkill, use linear models)\n",
    "- Extreme real-time latency requirements\n",
    "\n",
    "**Best use case: Structured/tabular data with complex patterns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8cb95",
   "metadata": {},
   "source": [
    "**Main Hyperparameters**\n",
    "\n",
    "A. **n_estimators (number of trees):**\n",
    "\n",
    "- More trees = better performance, but diminishing returns\n",
    "- More trees = slower training/prediction\n",
    "\n",
    "- Typical values: [50, 100, 200, 500]\n",
    "- Start with 100\n",
    "- If computational budget allows → 200-500\n",
    "- More is almost always better (just slower)\n",
    "- Intuition: More trees = more opinions = more stable\n",
    "\n",
    "B. **max_depth:**\n",
    "\n",
    "- None (default): Trees grow fully → individual trees overfit, but ensemble handles it\n",
    "- Limit (5-20): Prevents individual trees from overfitting too much\n",
    "\n",
    "- Typical values: [None, 10, 20, 30]\n",
    "\n",
    "- Often can leave as None (RF handles overfitting via averaging)\n",
    "- If very large dataset → limit to speed up training\n",
    "\n",
    "- Difference from single tree: RF is MORE robust to deep trees than single tree\n",
    "\n",
    "C. **min_samples_split:**\n",
    "\n",
    "- Default: 2\n",
    "- Higher (10, 20): Simpler trees\n",
    "\n",
    "- Typical values: [2, 5, 10, 20]\n",
    "\n",
    "- Less critical than for single tree (averaging helps)\n",
    "\n",
    "D. **min_samples_leaf:**\n",
    "\n",
    "- Default: 1\n",
    "- Higher (5, 10): Smoother predictions\n",
    "\n",
    "- Typical values: [1, 2, 5, 10]\n",
    "\n",
    "- Increase if overfitting (though RF less prone to this)\n",
    "\n",
    "E. **max_features (features considered per split):**\n",
    "\n",
    "- 'sqrt' (default for classification): √(n_features)\n",
    "- 'log2': log₂(n_features)\n",
    "- None: All features (reduces diversity)\n",
    "- int/float: Specific number or fraction\n",
    "\n",
    "- Typical values: ['sqrt', 'log2', 0.3, 0.5]\n",
    "\n",
    "- 'sqrt' is good default\n",
    "- Lower → more diversity, less overfitting\n",
    "- Higher → stronger trees, more correlation\n",
    "\n",
    "- Intuition: Controls diversity of trees\n",
    "\n",
    "- Fewer features → trees more different → less correlation → better averaging\n",
    "\n",
    "F. **max_samples (bootstrap sample size):**\n",
    "\n",
    "- None (default): Use all samples (with replacement)\n",
    "- Float (0.5, 0.8): Use fraction of samples per tree\n",
    "\n",
    "- Typical values: [None, 0.6, 0.8]\n",
    "\n",
    "- Lower → faster training, more diversity\n",
    "- Higher → stronger individual trees\n",
    "\n",
    "G. **n_jobs:**\n",
    "\n",
    "- -1: Use all CPU cores (parallel training)\n",
    "- 1: Single core\n",
    "- Always use -1 for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING FOR Random Forest\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2', 0.3]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV (faster than GridSearch for RF)\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Try 20 random combinations\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Best params: {random_search.best_params_}\")\n",
    "print(f\"Best AUC: {random_search.best_score_:.3f}\")\n",
    "\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6313f",
   "metadata": {},
   "source": [
    "**Random Forest feature importance has biases:**\n",
    "\n",
    "A. **Biased toward high-cardinality features:**\n",
    "\n",
    "- Features with more unique values get higher importance\n",
    "- Not always reflective of true predictive power\n",
    "\n",
    "B. **Correlated features:**\n",
    "\n",
    "- Importance split between correlated features\n",
    "- May underestimate importance of any single correlated feature\n",
    "\n",
    "C. **Not causal:**\n",
    "\n",
    "- High importance ≠ causes outcome\n",
    "- Just means useful for prediction\n",
    "\n",
    "Alternative: **Permutation Importance** \n",
    "- Shuffle feature, measure drop in performance\n",
    "- More reliable than built-in performance \n",
    "- Slower computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    model, X_test, y_test, n_repeats=10, random_state=42\n",
    ")\n",
    "\n",
    "importance_perm = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': perm_importance.importances_mean\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aede0d",
   "metadata": {},
   "source": [
    "**Why Random Forest:**\n",
    "\n",
    "- Ensemble of trees fixes instability of single decision tree\n",
    "- Resistant to overfitting through averaging\n",
    "- Handles non-linearity, interactions, outliers naturally\n",
    "- No feature scaling needed\n",
    "- Provides feature importance\n",
    "\n",
    "**Hyperparameter strategy:**\n",
    "\n",
    "- Start with n_estimators=100-200 (more if time allows)\n",
    "- Keep max_depth=None initially (RF handles deep trees)\n",
    "- Tune min_samples_leaf if overfitting (5-10)\n",
    "- Use n_jobs=-1 for parallel training\n",
    "- Monitor OOB score for quick validation\n",
    "\n",
    "**Expected performance:**\n",
    "\n",
    "- Should significantly beat single decision tree\n",
    "- Comparable to or slightly below XGBoost (but easier to tune)\n",
    "- AUC typically 0.75-0.90 for good problems\n",
    "\n",
    "**When to switch:**\n",
    "\n",
    "- Need max performance → XGBoost/LightGBM\n",
    "- Need interpretability → Single tree or linear model\n",
    "- Very large data → LightGBM (faster)\n",
    "\n",
    "Random Forest is my baseline for complex tabular data - works reliably with minimal tuning\n",
    "\n",
    "\n",
    "| Aspect | Random Forest | Single Decision Tree | Gradient Boosting |\n",
    "|--------|---------------|----------------------|-------------------|\n",
    "| **Overfitting** | ✅ Resistant | ❌ Prone | ⚠️ Can overfit if not tuned |\n",
    "| **Interpretability** | ⚠️ Medium | ✅ High | ❌ Low |\n",
    "| **Training speed** | ⚠️ Medium | ✅ Fast | ❌ Slow |\n",
    "| **Prediction speed** | ⚠️ Medium | ✅ Fast | ⚠️ Medium |\n",
    "| **Performance** | ✅ Good | ⚠️ Medium | ✅ Best |\n",
    "| **Hyperparameter tuning** | ✅ Easy | ✅ Easy | ❌ Requires care |\n",
    "| **Stability** | ✅ Stable | ❌ Unstable | ✅ Stable |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL CLASSIFICATION IMPLEMENTATION - RF \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9495da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL REGRESSION IMPLEMENTATION - RF\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.2f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899297f8",
   "metadata": {},
   "source": [
    "### **8.1. Evaluating Classification**\n",
    "\n",
    "1. **Confusion Matrix**\n",
    "- TP (True Positive): Correctly predicted positive\n",
    "- TN (True Negative): Correctly predicted negative\n",
    "- FP (False Positive): Predicted positive, actually negative (Type I error)\n",
    "- FN (False Negative): Predicted negative, actually positive (Type II error)\n",
    "\n",
    "```\n",
    "                      PREDICTED             \n",
    "                 Negative  Positive         \n",
    "              ┌──────────┬──────────┐        \n",
    "ACTUAL   Neg  │    TN    │    FP    │        \n",
    "              ├──────────┼──────────┤       \n",
    "         Pos  │    FN    │    TP    │       \n",
    "              └──────────┴──────────┘        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['No Churn', 'Churn'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d838d3",
   "metadata": {},
   "source": [
    "2. **Accuracy**: What percentage of predictions are correct\n",
    "\n",
    "   **When to use:**\n",
    "\n",
    "- Balanced classes (50/50 or 60/40)\n",
    "- All errors equally costly\n",
    "\n",
    "   **When NOT to use:**\n",
    "\n",
    "- Imbalanced data (99% one class → 99% accuracy by always predicting majority)\n",
    "- Example: Email spam (95% legitimate, 5% spam)\n",
    "- Predict \"all legitimate\" → 95% accuracy but catches zero spam!\n",
    "\n",
    "**(TP + TN) / (TP + TN + FP + FN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ec367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Or: (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc6ee6",
   "metadata": {},
   "source": [
    "3. **Precision**: What percentage of positive predictions were correct\n",
    "\n",
    "   When to use:\n",
    "\n",
    "- Cost of False Positives is HIGH\n",
    "- Don't want false alarms\n",
    "\n",
    "   Examples:\n",
    "\n",
    "- Spam filter: Don't want to mark important emails as spam (FP bad)\n",
    "- Medical diagnosis for expensive treatment: Don't give treatment to healthy people (FP expensive)\n",
    "\n",
    "   **TP / (TP + FP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a0c7cd",
   "metadata": {},
   "source": [
    "4. **Recall**: What percentage of actual positives did we catch. \"Of all the actual cases, how many did I find?\" \n",
    "\n",
    "   When to use:\n",
    "\n",
    "- Cost of False Negatives is HIGH\n",
    "- Can't afford to miss positives\n",
    "\n",
    "   Examples:\n",
    "\n",
    "- Cancer screening: Can't miss cancer cases (FN catastrophic)\n",
    "- Fraud detection: Missing fraud costs money (FN expensive)\n",
    "- Churn prediction: Missing churners loses customers (FN costly)\n",
    "\n",
    "  **TP / (TP + FN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2754f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f466c",
   "metadata": {},
   "source": [
    "5. **F1-Score**: Harmonic mean of Precision and Recall\n",
    "\n",
    "   When to use:\n",
    "\n",
    "- Need balance between Precision and Recall\n",
    "- Imbalanced classes\n",
    "- Single metric needed\n",
    "\n",
    "   Context: F1 = 0.8 means good balance of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35693a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3ea32",
   "metadata": {},
   "source": [
    "6. **ROC and AUC**\n",
    "\n",
    "- ROC Curve: True Positive Rate vs False Positive Rate at different thresholds\n",
    "- AUC (Area Under Curve): Single number summarizing ROC\n",
    "\n",
    "  **AUC Interpretation:**\n",
    "\n",
    "- AUC = 0.5: Random guessing (worthless model)\n",
    "- AUC = 0.7-0.8: Fair model\n",
    "- AUC = 0.8-0.9: Good model\n",
    "- AUC = 0.9-1.0: Excellent model\n",
    "- AUC = 1.0: Perfect (or data leakage!)\n",
    "\n",
    "  **When to use:**\n",
    "\n",
    "- Comparing models overall\n",
    "- Threshold-independent metric\n",
    "- Imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e144b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c40379",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "Step 1 - Check confusion matrix:\n",
    "\n",
    "- Understand TP, TN, FP, FN distribution\n",
    "- Identify which errors are happening\n",
    "\n",
    "Step 2 - Choose primary metric based on business:\n",
    "\n",
    "- Churn prediction: Optimize Recall (can't afford to miss churners - FN costly)\n",
    "- Fraud detection: Balance Precision and Recall (F1-score or tune threshold)\n",
    "- Spam filter: Optimize Precision (don't mark important emails as spam - FP bad)\n",
    "\n",
    "Step 3 - Use AUC for model comparison:\n",
    "\n",
    "- Threshold-independent\n",
    "- AUC > 0.8 is good, > 0.9 is excellent\n",
    "- If AUC = 1.0, check for data leakage\n",
    "\n",
    "Step 4 - Adjust threshold if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6dc9f9",
   "metadata": {},
   "source": [
    "### **8.2. Regression Evaluation**\n",
    "\n",
    "1. **Mean Absolute Esrror (MAE)**\n",
    "\n",
    "- Formula: Average of |actual - predicted|\n",
    "- Interpretation: \"On average, predictions are off by $X\"\n",
    "  \n",
    "\n",
    "- Easy to interpret (same units as target)\n",
    "- All errors treated equally\n",
    "- Robust to outliers (compared to RMSE)\n",
    "\n",
    "  Example: MAE = $5,000 means average error is $5,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebecdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b932a",
   "metadata": {},
   "source": [
    "2. **Root Mean Squared Error (MSE/RMSE)**\n",
    "\n",
    "- Penalizes large errors more\n",
    "- MSE Formula: Average of (actual - predicted)²\n",
    "- RMSE Formula: √MSE\n",
    "\n",
    "- Large errors are particularly bad\n",
    "- Most common regression metric\n",
    "- Interpretable (RMSE in original units)\n",
    "\n",
    "  **Difference from MAE:**\n",
    "- RMSE penalizes large errors more (squared)\n",
    "- Error of $10K contributes more than 2× error of $5K\n",
    "\n",
    "- Example: RMSE = $8,000 means typical error is around $8,000, with extra penalty on large errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0987ba3",
   "metadata": {},
   "source": [
    "3. **R Squared (R2)**\n",
    "\n",
    "- Percentage of variance explained by model\n",
    "\n",
    "- Formula: 1 - (Sum of squared residuals / Total sum of squares)\n",
    "- Range: -∞ to 1\n",
    "\n",
    "- R² = 1: Perfect predictions\n",
    "- R² = 0: Model no better than predicting mean\n",
    "- R² < 0: Model worse than predicting mean\n",
    "\n",
    "   **When to Use:**\n",
    "- Comparing models\n",
    "- Understanding model fit quality\n",
    "- Standard regression metric\n",
    "\n",
    "  **Interpretation:**\n",
    "\n",
    "- R² = 0.85 means model explains 85% of variance in target\n",
    "- Remaining 15% is unexplained (noise, missing features)\n",
    "\n",
    "  **Limitation:** Can be misleading with non-linear relationships or outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9d57b",
   "metadata": {},
   "source": [
    "RMSE = $45K means typical prediction error is $45,000\n",
    "R² = 0.85 means model explains 85% of price variation\n",
    "If R² < 0.5, model not capturing patterns well (need better features or model)\n",
    "\n",
    "Validate with residual plot:\n",
    "\n",
    "Random scatter = good model fit\n",
    "Patterns = model missing something (non-linearity, heteroscedasticity)\n",
    "\n",
    "Choose based on business:\n",
    "\n",
    "- If large errors particularly costly → RMSE\n",
    "- If prefer equal weighting of errors → MAE\n",
    "- If want % → MAPE\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
